{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.segmentation as seg\n",
    "import skimage.transform as tran\n",
    "from skimage import io, filters, transform, color, measure, segmentation, morphology, feature,img_as_ubyte\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_segmentation(img):\n",
    "    \n",
    "    ##knn\n",
    "    label_image = segmentation.slic(img,n_segments = 7)\n",
    "    image_label_overlay = color.label2rgb(label_image,image = img)\n",
    "\n",
    "    ##tresh\n",
    "    #image = color.rgb2gray(img)\n",
    "    #thresh =filters.threshold_otsu(image)\n",
    "    #bw =morphology.closing(image > thresh, morphology.square(3))\n",
    "    \n",
    "    #cleared = bw.copy() \n",
    "    #segmentation.clear_border(cleared) \n",
    "    #label_image =measure.label(cleared) \n",
    "    #borders = np.logical_xor(bw, cleared)\n",
    "    #label_image[borders] = -1\n",
    "    #image_label_overlay =color.label2rgb(label_image, image=image)\n",
    "    #fig,(ax0,ax1)= plt.subplots(1,2, figsize=(8, 6))\n",
    "\n",
    "    #ax0.imshow(cleared,plt.cm.gray)\n",
    "    #ax1.imshow(image_label_overlay)\n",
    "    \n",
    "    MR1 = 0\n",
    "    MR2 = 0\n",
    "    MC1 = 0\n",
    "    MC2 = 0\n",
    "    A,B = img.shape[:2]\n",
    "    dis = max(A,B)\n",
    "    a = A/2\n",
    "    b = B/2\n",
    "\n",
    "    for region in measure.regionprops(label_image):\n",
    "\n",
    "        if region.area < 400:\n",
    "            continue\n",
    "\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        d = (maxc - minc)/2 + minc\n",
    "        c = (maxr - minr)/2 + minr\n",
    "        D = distance(a,b,c,d)\n",
    "        #rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "        #                          fill=False, edgecolor='red', linewidth=2)\n",
    "        #ax1.add_patch(rect)\n",
    "        if D < dis:\n",
    "        #if (abs(maxc - minc)* abs(maxr - minr)) > (abs(MC2-MC1)* abs(MR2-MR1)):\n",
    "            MR1 = minr\n",
    "            MR2 = maxr\n",
    "            MC1 = minc\n",
    "            MC2 = maxc\n",
    "            dis = D\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    #roi = color.rgb2gray(img)\n",
    "    #thresh = 140\n",
    "    #bw = (roi <= thresh/255) * 1\n",
    "    #pic_temp2 = imfill(bw)\n",
    "    #cleared = pic_temp2.copy()  \n",
    "    #segmentation.clear_border(cleared)\n",
    "    #label_image = measure.label(cleared) \n",
    "    #borders = np.logical_xor(bw, cleared)  \n",
    "    #label_image[borders] = -1\n",
    "    #Eccentricity = 1   \n",
    "    #for region in measure.regionprops(label_image):\n",
    "    #   if region.area < 100:\n",
    "    #        continue\n",
    "    #    print('area is ' + str(region.area) + '  ecc is' + str(region.eccentricity))\n",
    "    #    if Eccentricity > region.eccentricity:\n",
    "    #        Eccentricity = region.eccentricity\n",
    "    #        minr, minc, maxr, maxc = region.bbox \n",
    "    \n",
    "    if 'MR1' in vars():\n",
    "        pic = img[MR1:MR2, MC1:MC2,:]\n",
    "        pic = transform.resize(pic, [256,256,3])\n",
    "        #print(lbp)\n",
    "        #plt.imshow(pic)\n",
    "        #plt.show()\n",
    "    else:\n",
    "        pic = transform.resize(img, [256, 256, 3])\n",
    "        \n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a,b,c,d):\n",
    "    p1=np.array([a,b])\n",
    "    p2=np.array([c,d])\n",
    "    p3=p2-p1\n",
    "    p4=math.hypot(p3[0],p3[1])\n",
    "    \n",
    "    return p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imfill(im_th):\n",
    "    \n",
    "    # Copy the thresholded imapge.\n",
    "    im_th = np.uint8(im_th)\n",
    "    im_floodfill = im_th.copy()\n",
    "    # Mask used to flood filling.\n",
    "    # Notice the size needs to be 2 pixels than the image.\n",
    "    h, w = im_th.shape[:2]\n",
    "    # print('h '+str(h)+'   w '+str(w))\n",
    "    mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "    # Floodfill from point (0, 0)\n",
    "    cv2.floodFill(im_floodfill, mask, (0, 0), 1)\n",
    "    # Invert floodfilled image\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "    # Combine the two images to get the foreground.\n",
    "    im_out = im_th | im_floodfill_inv\n",
    "    return im_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] #image paths\n",
    "Y = [] #image labels\n",
    "\n",
    "n = 8\n",
    "for i in range(1,n+1):\n",
    "    for f in os.listdir('.\\\\photo\\\\%s' % i):\n",
    "        X.append('.\\\\photo\\\\' +str(i) + '\\\\' + str(f))\n",
    "        Y.append(i)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LBP_feature(I):\n",
    "    pic1 = color.rgb2gray(I)\n",
    "    rows, cols = pic1.shape\n",
    "    radius = 4;\n",
    "    n_points = radius * 8\n",
    "    lbp_sum=[]\n",
    "    for row in range(radius):\n",
    "        for col in range(radius):\n",
    "            #print(str((row * rows//2)) + ' : ' + str(((row+1) * rows//2 - 1)))\n",
    "            pic1_block = pic1[(row * rows//2) : ((row+1) * rows//2 - 1) , (col * col//2) : ((col+1) * col//2 - 1)]\n",
    "            lbp = feature.local_binary_pattern(pic1, n_points, radius, 'uniform')\n",
    "            lbp2 = lbp.astype(np.int32)\n",
    "            max_bins = int(lbp2.max() + 1)\n",
    "            train_hist, _ = np.histogram(lbp2, normed = True, bins=max_bins, range=(0, max_bins))\n",
    "           # print(train_hist.dtype)\n",
    "            #print(train_hist)\n",
    "            lbpfeature=lbp_sum + train_hist.tolist()\n",
    "    return lbpfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_feature(I):\n",
    "    #img = cv2.cvtColor(np.array(I),cv2.COLOR_RGB2BGR)\n",
    "    #r,g,b = cv2.split(I)\n",
    "    #bgr_image = cv2.merge([b,g,r])\n",
    "    #bgr_image = bgr_image*255\n",
    "    hist = cv2.calcHist([I],[0,1],None,[256,256], [0.0,255.0,0.0,255.0])\n",
    "    histfeature = (hist/255).flatten()\n",
    "    return histfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image segmentation\n",
    "\n",
    "#image_show = []\n",
    "i = 0\n",
    "X_path = []\n",
    "\n",
    "for path in X:\n",
    "    if os.path.exists(path):\n",
    "        img = io.imread(path)\n",
    "        \n",
    "        I = image_segmentation(img)\n",
    "        io.imsave('./photo_seg/%s.png' %i,img_as_ubyte(I))\n",
    "        X_path.append('./photo_seg/%s.png' %i)\n",
    "        #image_show.append(I)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "X_lbp = []\n",
    "\n",
    "\n",
    "for path in X_path:\n",
    "    I = io.imread(path)\n",
    "    feature1 = LBP_feature(I)\n",
    "    X_lbp.append(feature1)\n",
    "    \n",
    "    print(path[12:])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hist = []\n",
    "for path in X:\n",
    "    I = cv2.imread(path)\n",
    "    image = cv2.resize(I, (256,256),interpolation=cv2.INTER_CUBIC)\n",
    "    feature2 = hist_feature(image)\n",
    "    X_hist.append(feature2)\n",
    "    \n",
    "    print(path[12:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SAVE\n",
    "LBP = open('LBP.pickle','wb')\n",
    "pickle.dump(X_lbp,LBP)\n",
    "LBP.close()\n",
    "\n",
    "HIST = open('HIST.pickle','wb')\n",
    "pickle.dump(X_hist,HIST)\n",
    "HIST.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature read\n",
    "LBP = open('LBP.pickle','rb')\n",
    "X_lbp = pickle.load(LBP)\n",
    "#print(X_lbp)\n",
    "\n",
    "HIST = open('HIST.pickle','rb')\n",
    "X_hist = pickle.load(HIST)\n",
    "#print(X_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbp\n",
    "X_lbp_train, X_lbp_test, y_lbp_train, y_lbp_test = train_test_split(X_lbp, Y,test_size=0.3, random_state=0)\n",
    "#hist\n",
    "X_hist_train, X_hist_test, y_hist_train, y_hist_test = train_test_split(X_hist, Y,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, multiclass, model_selection\n",
    "svr_rbf = svm.SVR(kernel='rbf', C=1e3, gamma=0.1);\n",
    "model = multiclass .OneVsRestClassifier(svr_rbf,-1)  #.fit(train_data, train_label).score(test_data,test_label)\n",
    "clf_lbp = model.fit(X_lbp_train, y_lbp_train)\n",
    "predictions_labels_lbp = clf_lbp.predict(X_lbp_test)\n",
    "\n",
    "print ('Evaluation:')\n",
    "print (classification_report(y_lbp_test, predictions_labels_lbp))\n",
    "\n",
    "print('Score:')\n",
    "sore_lbp=clf_lbp.score(X_lbp_test, y_lbp_test)\n",
    "print(sore_lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_hist = BernoulliNB().fit(X_hist_train, y_hist_train)\n",
    "predictions_labels_hist = clf_hist.predict(X_hist_test)\n",
    "\n",
    "#print ('Prediction:')\n",
    "#print (predictions_labels_hist)\n",
    "\n",
    "print ('Evaluation:')\n",
    "print (classification_report(y_hist_test, predictions_labels_hist))\n",
    "\n",
    "print('Score:')\n",
    "score_hist = clf_hist.score(X_hist_test,y_hist_test)\n",
    "print(score_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(clf_hist, 'clf_hist.model')\n",
    "joblib.dump(clf_lbp, 'clf_lbp.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_parameter(Report_list,N):\n",
    "    #n = len(Report_list)\n",
    "    #M = N**n\n",
    "    P = np.zeros(shape=(N,N**2))\n",
    "    \n",
    "    P_L = np.zeros(shape=(N,N))\n",
    "    P_H = np.zeros(shape=(N,N))\n",
    "    \n",
    "    #P(O|L)\n",
    "    for a in range(N):\n",
    "        p = round(Report_list[0][str(a+1)]['precision'],2)\n",
    "        for j in range(N):\n",
    "            if j == a:\n",
    "                P_L[j][a] = p\n",
    "            else:\n",
    "                P_L[j][a] = (1-p)/(N-1)\n",
    "    print('parameter A:')\n",
    "    print(P_L)\n",
    "    \n",
    "    #P(O=j|H=b)\n",
    "    for b in range(N):\n",
    "        p = round(Report_list[1][str(b+1)]['precision'],2)\n",
    "        for j in range(N):\n",
    "            if j == b:\n",
    "                P_H[j][b] = p\n",
    "            else:\n",
    "                P_H[j][b] = (1-p)/(N-1)\n",
    "    print('parameter B:')\n",
    "    print(P_H)\n",
    "    \n",
    "    #P(O=j|L=a,H=b)=P(O=j|L=a)*P(O=j|H=b)\n",
    "    for j in range(N):\n",
    "        for b in range(N):\n",
    "            for a in range(N):\n",
    "                i = b * N + a\n",
    "                #print(P.shape,i,j,a,b)\n",
    "                P[j,i] = (P_L[a][j]*P_H[b][j])/(1/N)\n",
    "    print('Conditional Probability Distribution:')\n",
    "    print(P)\n",
    "    \n",
    "    return P,P_L,P_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LBP_predict = clf_lbp.predict(X_lbp_train)\n",
    "Hist_predict = clf_hist.predict(X_hist_train)\n",
    "\n",
    "LBP_test = clf_lbp.predict(X_lbp_test)\n",
    "Hist_test = clf_hist.predict(X_hist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  {'lbp':LBP_predict,'hist':Hist_predict,'object':y_lbp_train}\n",
    "values = pd.DataFrame(data)\n",
    "\n",
    "test = {'lbp':LBP_test,'hist':Hist_test,'object':y_lbp_test}\n",
    "test_values = pd.DataFrame(test)\n",
    "\n",
    "true_object = pd.DataFrame({'object':y_lbp_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values.drop('object', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianModel\n",
    "#values = pd.DataFrame(np.random.randint(low=0, high=2, size=(1000, 5)),\n",
    "#                      columns=['A', 'B', 'C', 'D', 'E'])\n",
    "#train_data = values[:800]\n",
    "#predict_data = values[800:]\n",
    "model = BayesianModel([('lbp', 'object'), ('hist', 'object')])\n",
    "model.fit(values)\n",
    "predict_data = test_values.copy()\n",
    "#test_values.drop('object', axis=1, inplace=True)\n",
    "y_pred = model.predict(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.insert(1,'true',true_object['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "N = len(y_lbp_test)\n",
    "for i in (np.array(y_pred['object'])-np.array(y_pred['true'])):\n",
    "    if i != 0:\n",
    "        print(i)\n",
    "        num += 1\n",
    "print(num,N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
